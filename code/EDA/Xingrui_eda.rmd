
First join some dataset together

```{r}
library(readr)
library(tidyverse)

heat_check <- read_csv("../../data/heat_check_tournament_index.csv")
big_dance <- read_csv("../../data/Big_Dance_CSV.csv")
kenpom_data <- read_csv("../../data/kenpom_tournament_clean.csv")
tournament_matchups <- read_csv("../../data/tournament_matchups.csv")

# Inspect the data
head(heat_check)
head(big_dance)
head(kenpom_data)
head(tournament_matchups)
```


```{r}
heat_check <- heat_check %>% rename(Season = YEAR)
big_dance <- big_dance %>% rename(Season = Year)
names(big_dance) <- str_replace(names(big_dance), "\\...\\d+$", "")
tournament_matchups <- tournament_matchups %>% rename(Season = YEAR)
kenpom_data <- kenpom_data %>%
  select(-1)
```

```{r}
seed_expectations <- c(
  `1`=5,
  `2`=4,    
  `3`=4,    
  `4`=3,    
  `5`=3,
  `6`=2,   
  `7`=2,    
  `8`=2,    
  `9`=1,    
  `10`=1,   
  `11`=1,   
  `12`=1,   
  `13`=0,  
  `14`=0,
  `15`=0,   
  `16`=0    
)

# 1 means  elite eight or better
# 2 - 3 means sweet sixteen or better
# 4 -8 means round of 32 or better
# 9 - 12 means the team enter first round
# 13 - 16 means typically lose in first round

# Analyze upsets based on PATH difficulty
heat_check <- heat_check %>%
  mutate(Upset = ROUND > seed_expectations[as.character(SEED)]) %>%
  mutate(Upset = ifelse(Upset, "Upset", "No Upset"))

# Visualizing the distribution of PATH difficulty for Upsets
ggplot(heat_check, aes(x=Upset, y=PATH, fill=Upset)) +
  geom_violin(trim=FALSE) +
  labs(title="Distribution of Path Difficulty Based on Upset Status", x="Upset Status", y="Path Difficulty") +
  theme_minimal()
```


```{r}
library(dplyr)
library(caret)
library(e1071)

# Assuming the dataset 'heat_check' is already loaded
# Clean and prepare the data
features <- heat_check %>%
  select(SEED, PATH, POWER, `POWER-PATH`, WINS, Upset) %>%
  na.omit()  # Remove rows with NA values

# Convert 'Upset' to a factor
features$Upset <- as.factor(features$Upset)

# Split the data into training and testing sets
set.seed(123)  # for reproducibility
training_indices <- createDataPartition(features$Upset, p=0.8, list=FALSE)
training_data <- features[training_indices, ]
testing_data <- features[-training_indices, ]


```


```{r}
# Training the SVM model
svm_model <- svm(Upset ~ ., data=training_data, type='C-classification', kernel='radial')

# Print a summary to check model details
summary(svm_model)

```

```{r}
# Making predictions on the testing dataset
predictions <- predict(svm_model, testing_data)

# Creating a confusion matrix to evaluate the model
confusionMatrix <- table(Predicted=predictions, Actual=testing_data$Upset)

# Calculate accuracy
accuracy <- sum(diag(confusionMatrix)) / sum(confusionMatrix)
print(paste("Accuracy: ", accuracy))

```



